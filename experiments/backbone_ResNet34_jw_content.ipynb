{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"P31ZlvuDxSzY","executionInfo":{"status":"ok","timestamp":1764262652328,"user_tz":-540,"elapsed":17910,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"outputs":[],"source":["# ========================================================\n","# 1. ğŸ› ï¸ í™˜ê²½ ì„¤ì • ë° ê²½ë¡œ, Import (Code Block 1/2)\n","# ========================================================\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Subset\n","import torchvision.models as models\n","import pandas as pd\n","import numpy as np\n","import random\n","import os\n","import sys\n","from tqdm import tqdm\n","from typing import Tuple, Dict, List\n","from google.colab import drive\n","from sklearn.metrics.pairwise import cosine_similarity\n","from torch.utils.data.dataloader import default_collate\n","from typing import List, Dict\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21130,"status":"ok","timestamp":1764262673472,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"},"user_tz":-540},"id":"ACpB338K0748","outputId":"a726de46-4394-4a87-c821-6fcd8f5c2298"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# ë§ˆìš´íŠ¸ (ê³µìœ  ë“œë¼ì´ë¸Œ ê²½ë¡œê°€ MyDriveì— ë°”ë¡œ ì—°ê²°ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)\n","drive.mount('/content/drive')\n","\n","# --- ê²½ë¡œ ì„¤ì • ---\n","# ğŸš¨ [í†µì¼ í•„ìˆ˜] ê³µìœ  ë“œë¼ì´ë¸Œ ê²½ë¡œì™€ íŒŒì¼ëª…\n","# ì´ ê²½ë¡œê°€ dataset.py, transforms.py, checkpoints í´ë”ê°€ ìˆëŠ” ìœ„ì¹˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\n","MODULE_PATH = \"/content/drive/MyDrive/2025CV\"\n","sys.path.append(MODULE_PATH)\n"]},{"cell_type":"code","source":["# ### ì´ ì…€ë§Œ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤!!_11270646 ìŠ¹ì—°\n","# import os\n","\n","# SAVE_DIR = \"/content/drive/MyDrive/2025CV/best_weights_jw_content\"\n","\n","# os.makedirs(SAVE_DIR, exist_ok=True)\n","# print(\"Checkpoint ì €ì¥ í´ë” ìƒì„± ì™„ë£Œ:\", SAVE_DIR)\n"],"metadata":{"id":"nPkBPMF4RzJf","executionInfo":{"status":"ok","timestamp":1764262673476,"user_tz":-540,"elapsed":6,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# ğŸ’¡ Import Custom Modules (dataset.py, transforms.py)\n","# BBox í¬ë¡­ ë¡œì§ê³¼ Transforms ì •ì˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n","from dataset_jw import DeepFashionC2S\n","from transforms import train_transform, val_transform"],"metadata":{"id":"t5XkGI2OcSbo","executionInfo":{"status":"ok","timestamp":1764262676864,"user_tz":-540,"elapsed":3390,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1764262676908,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"},"user_tz":-540},"id":"G_vYkBF11EK4","outputId":"7671fa93-abb9-4882-96af-efa6cfa45030"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["# --- Hyperparameters (íŒ€ì› ê°„ í†µì¼ í•„ìˆ˜) ---\n","EXPERIMENT_SEED = 42\n","EMBEDDING_DIM = 128  # 128ë¡œ ê³ ì •\n","LEARNING_RATE = 1e-4\n","TRIPLET_MARGIN = 0.5 # Online Semi-Hard Triplet Loss ë§ˆì§„ ê°’\n","BATCH_SIZE = 32\n","PATIENCE = 5         # Early Stopping Patience (5 Epoch ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨)\n","MAX_EPOCHS = 40      # ìµœëŒ€ í•™ìŠµ Epoch ìˆ˜\n","CHECKPOINT_DIR = os.path.join(MODULE_PATH, \"checkpoint_jw_content\")\n","\n","os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {DEVICE}\")\n","\n","# ğŸš¨ ì¬í˜„ì„± í™•ë³´ë¥¼ ìœ„í•œ ì‹œë“œ ê³ ì •\n","def set_seed(seed):\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    return torch.Generator().manual_seed(seed)\n","\n","generator = set_seed(EXPERIMENT_SEED)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"vVz_Qlb51Hqh","executionInfo":{"status":"ok","timestamp":1764262676914,"user_tz":-540,"elapsed":3,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"outputs":[],"source":["\n","# --- CSV íŒŒì¼ ë¡œë“œ (ìƒ˜í”Œë§ëœ CSV ì‚¬ìš©) ---\n","CSV_PATH_LIGHT = os.path.join(MODULE_PATH, \"meta_c2s_10_2_2_sampling_ID.csv\")"]},{"cell_type":"code","source":["import os\n","import shutil\n","import pandas as pd\n","\n","# --- ê²½ë¡œ ì„¤ì • í™•ì¸ ---\n","\n","DRIVE_IMG_ROOT = os.path.join(MODULE_PATH, \"Images\") # ì›ë³¸ ì´ë¯¸ì§€ ë£¨íŠ¸ ê²½ë¡œ (Drive)\n","LOCAL_IMG_ROOT = \"/content/Images\"                   # íƒ€ê²Ÿ ì´ë¯¸ì§€ ë£¨íŠ¸ ê²½ë¡œ (Local)"],"metadata":{"id":"6embU8hmrO-9","executionInfo":{"status":"ok","timestamp":1764262676945,"user_tz":-540,"elapsed":15,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# =========================================================\n","# ì´ê²Œ 40ë¶„ ê±¸ë ¤ìš”\n","# ğŸ’¡ [ìˆ˜ì •] CSV ê¸°ë°˜ ì„ íƒì  ì´ë¯¸ì§€ ë¡œì»¬ ë³µì‚¬ ë° I/O ìµœì í™”\n","# =========================================================\n","print(\"ğŸš€ CSV ê¸°ë°˜ ì„ íƒì  ì´ë¯¸ì§€ ë¡œì»¬ ëŸ°íƒ€ì„ ë³µì‚¬ ì‹œì‘...\")\n","\n","# 1. CSV íŒŒì¼ ë¡œë“œ\n","try:\n","    df_light = pd.read_csv(CSV_PATH_LIGHT)\n","except FileNotFoundError:\n","    print(f\"âŒ ì˜¤ë¥˜: CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {CSV_PATH_LIGHT}\")\n","    exit()\n","\n","# 2. í•„ìš”í•œ ëª¨ë“  ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ì¶œ\n","# consumer_pathì™€ shop_path ì—´ì—ì„œ ìœ ë‹ˆí¬í•œ ê²½ë¡œë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n","required_paths = pd.concat([df_light['consumer_path'], df_light['shop_path']]).unique()\n","print(f\"ì´ {len(required_paths)}ê°œì˜ ìœ ë‹ˆí¬í•œ ì´ë¯¸ì§€ íŒŒì¼ì„ ë³µì‚¬í•©ë‹ˆë‹¤.\")\n","\n","# 3. ë¡œì»¬ íƒ€ê²Ÿ í´ë” ìƒì„±\n","os.makedirs(LOCAL_IMG_ROOT, exist_ok=True)\n","\n","# 4. íŒŒì¼ ë³µì‚¬ ë° í´ë” êµ¬ì¡° ìœ ì§€\n","copied_count = 0\n","for relative_path in required_paths:\n","    # ì›ë³¸ íŒŒì¼ ê²½ë¡œ (Drive)\n","    source_file_path = os.path.join(DRIVE_IMG_ROOT, relative_path)\n","\n","    # íƒ€ê²Ÿ íŒŒì¼ ê²½ë¡œ (Local)\n","    target_file_path = os.path.join(LOCAL_IMG_ROOT, relative_path)\n","\n","    # íƒ€ê²Ÿ ë””ë ‰í† ë¦¬ ìƒì„± (ì˜ˆ: /content/Images/img/TOPS/Summer_ ì— í•„ìš”í•œ í´ë” ìƒì„±)\n","    target_dir = os.path.dirname(target_file_path)\n","    os.makedirs(target_dir, exist_ok=True)\n","\n","    # íŒŒì¼ ë³µì‚¬\n","    try:\n","        if not os.path.exists(target_file_path):\n","             shutil.copy2(source_file_path, target_file_path)\n","             copied_count += 1\n","    except FileNotFoundError:\n","        # CSVì— ê²½ë¡œê°€ ìˆì§€ë§Œ ì‹¤ì œ Driveì— íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê±´ë„ˆëœë‹ˆë‹¤.\n","        print(f\"[ê²½ê³ ] ì›ë³¸ íŒŒì¼ì´ Driveì— ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€: {source_file_path}\")\n","    except Exception as e:\n","        print(f\"[ì˜¤ë¥˜] ë³µì‚¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ ({relative_path}): {e}\")\n","\n","print(f\"âœ… ë¡œì»¬ ë³µì‚¬ ì™„ë£Œ. ì´ {copied_count}ê°œì˜ íŒŒì¼ ë³µì‚¬ë¨.\")\n","\n","# =========================================================\n","# ğŸ’¡ [ì¶”ê°€] 3. IMG_ROOT_DIR ë³€ìˆ˜ë¥¼ ë¡œì»¬ ê²½ë¡œë¡œ ë³€ê²½\n","# =========================================================\n","# ê¸°ì¡´ ê²½ë¡œ ë³€ìˆ˜ë¥¼ ìƒˆë¡œìš´ ë¡œì»¬ ê²½ë¡œë¡œ ë®ì–´ì”ë‹ˆë‹¤.\n","IMG_ROOT_DIR = LOCAL_IMG_ROOT\n","\n","print(f\"ìƒˆë¡œìš´ ì´ë¯¸ì§€ ë£¨íŠ¸ ê²½ë¡œ: {IMG_ROOT_DIR}\")"],"metadata":{"id":"H_3ldDfXzwfx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d2825db-799c-485d-9c46-b817c6f4b10d","executionInfo":{"status":"ok","timestamp":1764266731240,"user_tz":-540,"elapsed":4054292,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ CSV ê¸°ë°˜ ì„ íƒì  ì´ë¯¸ì§€ ë¡œì»¬ ëŸ°íƒ€ì„ ë³µì‚¬ ì‹œì‘...\n","ì´ 10546ê°œì˜ ìœ ë‹ˆí¬í•œ ì´ë¯¸ì§€ íŒŒì¼ì„ ë³µì‚¬í•©ë‹ˆë‹¤.\n","âœ… ë¡œì»¬ ë³µì‚¬ ì™„ë£Œ. ì´ 10546ê°œì˜ íŒŒì¼ ë³µì‚¬ë¨.\n","ìƒˆë¡œìš´ ì´ë¯¸ì§€ ë£¨íŠ¸ ê²½ë¡œ: /content/Images\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"6YvjqWS-dlG6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764266731274,"user_tz":-540,"elapsed":41,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}},"outputId":"664265c6-ddd1-49d9-dbe0-93df5a7f368d"},"outputs":[{"output_type":"stream","name":"stdout","text":["ì´ unique item_id ê°œìˆ˜: 1467\n"]}],"source":["# ============================================\n","# item_id ë¬¸ìì—´ â†’ ìˆ«ì ë¼ë²¨ ë³€í™˜ ë§¤í•‘ ìƒì„±\n","# ============================================\n","\n","df_full = pd.read_csv(CSV_PATH_LIGHT)\n","unique_ids = df_full[\"item_id\"].unique()\n","\n","id2label = {id_str: idx for idx, id_str in enumerate(unique_ids)}\n","print(\"ì´ unique item_id ê°œìˆ˜:\", len(id2label))\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"TU0u3b3c1IV4","executionInfo":{"status":"ok","timestamp":1764266731285,"user_tz":-540,"elapsed":8,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"outputs":[],"source":["# ========================================================\n","# 2. ğŸ§  ëª¨ë¸ ë° ì†ì‹¤ í•¨ìˆ˜ ì •ì˜ (Stage 2 í•µì‹¬) (Code Block 2/2)\n","# ========================================================\n","\n","# ğŸš¨ ë°±ë³¸ ëª¨ë¸ í´ë˜ìŠ¤ (Feature Embedding)\n","class FeatureEmbedding(nn.Module):\n","    def __init__(self, backbone_name, embedding_dim):\n","        super().__init__()\n","\n","        # 1. ë°±ë³¸ ë¡œë“œ ë° ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ ì„¤ì •\n","        if backbone_name == 'ResNet-50':\n","            base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n","            num_ftrs = base_model.fc.in_features\n","\n","        elif backbone_name == 'ResNet-34':\n","            base_model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n","            num_ftrs = base_model.fc.in_features\n","\n","        elif backbone_name == 'EfficientNet-B3':\n","            base_model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n","            num_ftrs = base_model.classifier[1].in_features\n","\n","        else:\n","            raise ValueError(f\"Unknown backbone: {backbone_name}\")\n","\n","        # 2. íŠ¹ì§• ì¶”ì¶œê¸° (ë§ˆì§€ë§‰ FC ë ˆì´ì–´ ì œê±°)\n","        if 'ResNet' in backbone_name:\n","            self.feature_extractor = nn.Sequential(*list(base_model.children())[:-1])\n","            self.final_fc = nn.Linear(num_ftrs, embedding_dim)\n","        elif 'EfficientNet' in backbone_name:\n","            self.feature_extractor = base_model.features\n","            self.avgpool = nn.AdaptiveAvgPool2d(1)\n","            self.final_fc = nn.Linear(num_ftrs, embedding_dim)\n","\n","        self.bn = nn.BatchNorm1d(embedding_dim)\n","\n","    def forward(self, x):\n","        x = self.feature_extractor(x)\n","        if hasattr(self, 'avgpool'):\n","            x = self.avgpool(x)\n","\n","        x = x.view(x.size(0), -1)\n","        x = self.final_fc(x)\n","        x = self.bn(x)\n","        x = F.normalize(x, p=2, dim=1)\n","        return x.to(DEVICE)\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"KagI8InF1Rfv","executionInfo":{"status":"ok","timestamp":1764266731301,"user_tz":-540,"elapsed":10,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"outputs":[],"source":["# ğŸš¨ [í†µí•©] Online Semi-Hard Triplet Loss í•¨ìˆ˜\n","def pairwise_distance_sq(embeddings: torch.Tensor) -> torch.Tensor:\n","    \"\"\"ë°°ì¹˜ ë‚´ ëª¨ë“  ì„ë² ë”© ìŒ ì‚¬ì´ì˜ ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ ì œê³±ì„ ê³„ì‚°.\"\"\"\n","    dot_product = torch.matmul(embeddings, embeddings.t())\n","    square_norm = torch.diag(dot_product)\n","    distances = square_norm.unsqueeze(0) - 2.0 * dot_product + square_norm.unsqueeze(1)\n","    distances[distances < 0] = 0\n","    return distances\n","\n","# ğŸš¨ [í†µì¼ í•„ìˆ˜] ì˜¨ë¼ì¸ ì„¸ë¯¸-í•˜ë“œ íŠ¸ë¦½ë › ì†ì‹¤ í•¨ìˆ˜ (Semi-Hard Mining êµ¬í˜„)\n","def online_semi_hard_triplet_loss(embeddings: torch.Tensor, labels: torch.Tensor, margin: float) -> torch.Tensor:\n","    \"\"\"\n","    Online Semi-Hard Triplet Loss: ë§ˆì§„ì„ ìœ„ë°˜í•˜ì§€ë§Œ ê°€ì¥ ì–´ë µì§€ëŠ” ì•Šì€ Negativeë¥¼ ì„ íƒí•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµ.\n","    \"\"\"\n","    pair_dist = pairwise_distance_sq(embeddings)\n","    labels = labels.to(pair_dist.device)\n","    labels_eq = labels.unsqueeze(0).eq(labels.unsqueeze(1))\n","\n","    # Hard Positive (A-P ì¤‘ ê°€ì¥ ë¨¼ ê±°ë¦¬)\n","    dist_ap = pair_dist.clone()\n","    dist_ap[~labels_eq] = float('-inf')\n","    hard_positive_dist, _ = dist_ap.max(dim=1)\n","\n","    # Semi-Hard Negative (D(A,N) > D(A,P) ì´ë©´ì„œ ê°€ì¥ ê°€ê¹Œìš´ N)\n","    dist_an = pair_dist.clone()\n","    dist_an[labels_eq] = float('inf')\n","\n","    # Semi-Hard ì¡°ê±´: D(A,N) > D(A,P) + marginì„ ë§Œì¡±í•˜ëŠ” ì˜ì—­\n","    # ë§ˆì§„ ì¡°ê±´ì„ ìœ„ë°˜í•˜ì§€ ì•ŠëŠ” (A-P ê±°ë¦¬ê°€ A-Në³´ë‹¤ ì´ë¯¸ margin ì´ìƒ ì‘ì€) Nì„ ì°¾ê¸° ìœ„í•´ ë¶€ë“±í˜¸ë¥¼ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n","    # Triplet Loss: D(A,P) - D(A,N) + margin > 0 ì¸ íŠ¸ë¦½ë ›ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.\n","    # Semi-HardëŠ” D(A,P) < D(A,N) < D(A,P) + margin ì…ë‹ˆë‹¤.\n","\n","    # 1. Negative ì¤‘ ë§ˆì§„ì„ ìœ„ë°˜í•˜ì§€ ì•ŠëŠ” í›„ë³´ (D(A,N) > D(A,P))\n","    is_semi_hard_candidate = dist_an > hard_positive_dist.unsqueeze(1)\n","\n","    # 2. Semi-Hard Negative ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ìƒ˜í”Œ ì„ íƒ\n","    # D(A,N)ì´ D(A,P)ë³´ë‹¤ í¬ë©´ì„œ, A-P ë§ˆì§„(alpha)ì„ ë„˜ì§€ ì•ŠëŠ” ì˜ì—­ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ Nì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.\n","    # PyTorch ë‚´ì¥ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ë³µì¡í•œ ì¸ë±ì‹± ëŒ€ì‹  ì•ˆì •ì„±ì„ ìœ„í•´ D(A,N) > D(A,P)ì¸ ìƒ˜í”Œë§Œ ë‚¨ê¹ë‹ˆë‹¤.\n","    dist_an[~is_semi_hard_candidate] = float('inf')\n","    semi_hard_negative_dist, _ = dist_an.min(dim=1)\n","\n","    # Triplet Loss ê³„ì‚°: L = max(0, D(A, P)_hard - D(A, N)_semi_hard + margin)\n","    triplet_loss = hard_positive_dist - semi_hard_negative_dist + margin\n","    triplet_loss[triplet_loss < 0] = 0\n","\n","    num_hard_triplets = triplet_loss.gt(1e-16).float().sum()\n","# ========================================================\n","# 8ì—í­ ì˜¤ë¥˜ í›„ ì—¬ê¸°ìˆ˜ì •í•¨\n","# ========================================================\n","    if num_hard_triplets > 0:\n","        return triplet_loss.sum() / num_hard_triplets\n","    else:\n","        # âš ï¸ ì—¬ê¸°ê°€ í•µì‹¬: ê·¸ë˜í”„ì— ë¶™ì–´ìˆëŠ” \"0\"ì„ ë¦¬í„´\n","        # embeddings ì—ì„œ ë§Œë“¤ì–´ì§„ ê°’ì´ë¯€ë¡œ requires_grad=True ìœ ì§€ë¨\n","        return (embeddings * 0.0).sum()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"O0YIpFve10oG","executionInfo":{"status":"ok","timestamp":1764266731317,"user_tz":-540,"elapsed":9,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"outputs":[],"source":["# ========================================================\n","# 3. ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ ë° í•™ìŠµ ë£¨í”„ (ì •ë¦¬ ë²„ì „)\n","# ========================================================\n","\n","def get_checkpoint_paths(backbone_name: str):\n","    \"\"\"\n","    backbone_name ê¸°ì¤€ìœ¼ë¡œ ì¼ë°˜ ì²´í¬í¬ì¸íŠ¸ì™€ ë² ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ê²½ë¡œë¥¼ í•œ ë²ˆì— ìƒì„±.\n","    ì˜ˆ) ResNet-34, EfficientNet-B3 ë“±\n","    \"\"\"\n","    # ì¼ë°˜ ì²´í¬í¬ì¸íŠ¸ (ë§ˆì§€ë§‰ epoch ê¸°ì¤€)\n","    checkpoint_file = os.path.join(\n","        CHECKPOINT_DIR,\n","        f\"{backbone_name}_checkpoint.pth\"\n","    )\n","\n","    # ë² ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ (ìµœê³  val R@5 ê¸°ì¤€)\n","    best_file = os.path.join(\n","        CHECKPOINT_DIR,\n","        f\"{backbone_name}_best_weights.pth\"\n","    )\n","\n","    return checkpoint_file, best_file\n","\n","\n","def save_checkpoint(model, optimizer, epoch, best_val_metric, patience_count, filename):\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'best_val_metric': best_val_metric,  # Recall@K ê°’ (í´ìˆ˜ë¡ ì¢‹ìŒ)\n","        'patience_count': patience_count,\n","    }\n","\n","    # ìƒìœ„ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ë§Œë“¤ì–´ì£¼ê¸° (ì•ˆì „ì¥ì¹˜)\n","    os.makedirs(os.path.dirname(filename), exist_ok=True)\n","\n","    torch.save(checkpoint, filename)\n","\n","\n","def load_checkpoint(model, optimizer, filename):\n","    if not os.path.exists(filename):\n","        print(\"âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n","        # Recall@KëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ, best_val_metricì„ 0.0ìœ¼ë¡œ ì´ˆê¸°í™”\n","        return 0, 0.0, 0\n","\n","    checkpoint = torch.load(filename, map_location=DEVICE)\n","\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","    start_epoch = checkpoint['epoch'] + 1\n","    best_val_metric = checkpoint['best_val_metric']\n","    patience_counter = checkpoint['patience_count']\n","\n","    print(\n","        f\"âœ… í•™ìŠµ ì¬ê°œ: Epoch {start_epoch}ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤. \"\n","        f\"(ìµœê³  Recall@5: {best_val_metric:.4f})\"\n","    )\n","\n","    return start_epoch, best_val_metric, patience_counter\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"tFFI2p_-C3i3","executionInfo":{"status":"ok","timestamp":1764266731340,"user_tz":-540,"elapsed":18,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"outputs":[],"source":["def train_model(backbone_name, train_dl, val_dl, criterion):\n","\n","     # --- ì´ˆê¸°í™”/ë³µêµ¬ ---\n","    model = FeatureEmbedding(backbone_name, EMBEDDING_DIM).to(DEVICE)\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","    # ì²´í¬í¬ì¸íŠ¸ / ë² ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ í•œ ë²ˆì— ì„¤ì •\n","    checkpoint_file, best_file = get_checkpoint_paths(backbone_name)\n","\n","    # ì¼ë°˜ ì²´í¬í¬ì¸íŠ¸ì—ì„œ í•™ìŠµ ì¬ê°œ\n","    start_epoch, best_val_metric, patience_counter = load_checkpoint(\n","        model, optimizer, checkpoint_file\n","    )\n","\n","    # ğŸš¨ ì‹¤í—˜ ê¸°ë¡ ë³µêµ¬\n","    history_file = os.path.join(CHECKPOINT_DIR, f\"{backbone_name}_history.csv\")\n","    history = []\n","\n","    if os.path.exists(history_file) and os.path.getsize(history_file) > 0:\n","        try:\n","            history_df = pd.read_csv(history_file)\n","            if not history_df.empty:\n","                history = history_df.to_dict('records')\n","            else:\n","                raise pd.errors.EmptyDataError(\"DataFrame is empty after reading.\")\n","\n","        except pd.errors.EmptyDataError:\n","            print(f\"âš ï¸ {backbone_name}_history.csv íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ê¸°ë¡ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n","            history = []\n","        except Exception as e:\n","            print(f\"âš ï¸ History file loading error ({e.__class__.__name__}): {e}. Starting new history.\")\n","            history = []\n","\n","    # --- í•™ìŠµ ë£¨í”„ ---\n","    for epoch in range(start_epoch, MAX_EPOCHS):\n","\n","        print(f\"\\n--- Starting Epoch {epoch + 1}/{MAX_EPOCHS} for {backbone_name} ---\")\n","\n","        model.train()\n","        total_loss = 0\n","\n","        # Batch-All Triplet Lossë¥¼ ìœ„í•œ ë°ì´í„° ë¡œë”© ë£¨í”„\n","        for batch in tqdm(train_dl, desc=f\"Epoch {epoch+1} Train ({backbone_name})\", leave=False):\n","            consumer_imgs = batch[\"consumer\"].to(DEVICE)\n","            shop_imgs = batch[\"shop\"].to(DEVICE)\n","            item_ids = batch[\"item_id\"]\n","\n","            # ë¬¸ìì—´ item_id â†’ ìˆ«ì ë¼ë²¨ ë³€í™˜\n","            if isinstance(item_ids, (list, tuple)):\n","                item_ids = torch.tensor([id2label[i] for i in item_ids], dtype=torch.long)\n","            else:\n","                item_ids = torch.tensor([id2label[item_ids]], dtype=torch.long)\n","\n","            item_ids = item_ids.to(DEVICE)\n","\n","            # ì´ë¯¸ì§€/ë¼ë²¨ ë³‘í•©\n","            all_imgs = torch.cat([consumer_imgs, shop_imgs], dim=0)\n","            all_labels = torch.cat([item_ids, item_ids], dim=0)\n","\n","            # ëª¨ë¸ ì—…ë°ì´íŠ¸\n","            optimizer.zero_grad()\n","            embeddings = model(all_imgs)\n","            loss = criterion(embeddings, all_labels, TRIPLET_MARGIN)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","        avg_train_loss = total_loss / len(train_dl)\n","\n","        # --- ê²€ì¦ ë£¨í”„: ë§¤ ì—í¬í¬ë§ˆë‹¤ ì‹¤í–‰ ---\n","        val_recalls = calculate_recall_at_k(model, val_dl, DEVICE, ks=[1, 5, 10])\n","        val_metric = val_recalls['R@5']\n","\n","        print(\n","            f\"Epoch {epoch+1} | \"\n","            f\"Train Loss: {avg_train_loss:.4f} | \"\n","            f\"R@1: {val_recalls['R@1']:.3f} | \"\n","            f\"R@5: {val_recalls['R@5']:.3f} | \"\n","            f\"R@10: {val_recalls['R@10']:.3f}\"\n","        )\n","\n","        history.append({\n","            'epoch': epoch + 1,\n","            'train_loss': avg_train_loss,\n","            'val_R@1': val_recalls['R@1'],\n","            'val_R@5': val_recalls['R@5'],\n","            'val_R@10': val_recalls['R@10']\n","        })\n","\n","        # --- Early Stopping ---\n","        if val_metric > best_val_metric:\n","            best_val_metric = val_metric\n","            patience_counter = 0\n","\n","            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n","            save_checkpoint(\n","                model, optimizer, epoch, best_val_metric, patience_counter,\n","                best_file\n","            )\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= PATIENCE:\n","                print(f\"Early stopping triggered at epoch {epoch+1}.\")\n","                pd.DataFrame(history).to_csv(history_file, index=False)\n","                break\n","\n","\n","        # Epoch ì¢…ë£Œ ì‹œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n","        save_checkpoint(model, optimizer, epoch, best_val_metric, patience_counter, checkpoint_file)\n","\n","        # history ì €ì¥\n","        pd.DataFrame(history).to_csv(history_file, index=False)\n","\n","    # --- ìµœì¢… ê²°ê³¼ ì¶œë ¥ ---\n","    try:\n","        # ë² ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ë¡œë“œ\n","        load_checkpoint(model, optimizer, best_file)\n","\n","        # ìµœì¢… Best Recall@K ê³„ì‚°\n","        final_recalls = calculate_recall_at_k(model, val_dl, DEVICE, ks=[1, 5, 10])\n","\n","        print(\"\\n========================================================\")\n","        print(f\"ğŸ† {backbone_name} Final Best R@1: {final_recalls['R@1']:.4f}\")\n","        print(f\"ğŸ† {backbone_name} Final Best R@5: {final_recalls['R@5']:.4f}\")\n","        print(f\"ğŸ† {backbone_name} Final Best R@10: {final_recalls['R@10']:.4f}\")\n","        print(\"========================================================\\n\")\n","\n","        return {\"backbone\": backbone_name, \"final_epoch\": epoch + 1, \"best_R@5\": final_recalls['R@5']}\n","\n","    except Exception as e:\n","        print(f\"Final evaluation failed: {e}\")\n","        return {\"backbone\": backbone_name, \"final_epoch\": epoch + 1, \"best_R@5\": 0.0}\n"]},{"cell_type":"code","source":["# ========================================================\n","# ğŸš¨ [ìµœì¢…ë³¸] calculate_recall_at_k í•¨ìˆ˜ (Dict Handling & Numeric Conversion)\n","# ========================================================\n","def calculate_recall_at_k(model, dataloader, device, ks=[1, 5, 10]):\n","    \"\"\"\n","    Validation Setì˜ ì„ë² ë”©ì„ ì¶”ì¶œí•˜ê³  Recall@K ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.\n","    (DataLoaderê°€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ê³ , item_idë¥¼ ìˆ«ì ë¼ë²¨ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©)\n","    \"\"\"\n","    model.eval()\n","    all_query_embs = []\n","    all_gallery_embs = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=f\"Calculating Recall@{ks[-1]}\"):\n","\n","            # ğŸš¨ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ batchì—ì„œ ë°ì´í„° ì¶”ì¶œ\n","            consumer_imgs = batch[\"consumer\"]\n","            shop_imgs = batch[\"shop\"]\n","            item_ids = batch[\"item_id\"] # ë¬¸ìì—´ (str) ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” íŠœí”Œ\n","\n","            # ğŸš¨ ë¬¸ìì—´ item_id â†’ ìˆ«ì ë¼ë²¨ ë³€í™˜ (train_modelê³¼ ë™ì¼í•œ ë¡œì§ ì ìš©)\n","            if isinstance(item_ids, list) or isinstance(item_ids, tuple):\n","                # ğŸš¨ Global id2label ë”•ì…”ë„ˆë¦¬ ì‚¬ìš© ê°€ì •\n","                item_ids_tensor = torch.tensor([id2label[i] for i in item_ids], dtype=torch.long)\n","            else:\n","                item_ids_tensor = torch.tensor([id2label[item_ids]], dtype=torch.long)\n","\n","            # ì„ë² ë”© ê³„ì‚°\n","            query_embs = model(consumer_imgs.to(device)).cpu().numpy()\n","            gallery_embs = model(shop_imgs.to(device)).cpu().numpy()\n","\n","            all_query_embs.append(query_embs)\n","            all_gallery_embs.append(gallery_embs)\n","            all_labels.append(item_ids_tensor.cpu().numpy()) # ìˆ«ì Tensorë¥¼ NumPy ë°°ì—´ë¡œ ì €ì¥\n","\n","    query_embs = np.concatenate(all_query_embs, axis=0)\n","    gallery_embs = np.concatenate(all_gallery_embs, axis=0)\n","    gallery_labels = np.concatenate(all_labels, axis=0) # [N,] í˜•íƒœì˜ ìˆ«ì ë°°ì—´\n","\n","    # 2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ê±°ë¦¬ í–‰ë ¬)\n","    sims = cosine_similarity(query_embs, gallery_embs)\n","\n","    recalls = {}\n","    for k in ks:\n","        # ìƒìœ„ Kê°œì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ (ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ)\n","        topk_idx = np.argsort(-sims, axis=1)[:, :k]\n","\n","        correct_count = 0\n","        for i in range(len(gallery_labels)):\n","            query_true_id = gallery_labels[i]\n","\n","            # ìƒìœ„ Kê°œì˜ ê°¤ëŸ¬ë¦¬ ìƒí’ˆ ID\n","            topk_ids = gallery_labels[topk_idx[i]]\n","\n","            # ğŸš¨ ì •ë‹µ IDê°€ ìƒìœ„ Kê°œ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ìˆ«ì ë¹„êµ)\n","            if query_true_id in topk_ids:\n","                correct_count += 1\n","\n","        recalls[f'R@{k}'] = correct_count / len(gallery_labels)\n","\n","    return recalls"],"metadata":{"id":"jV_InoDJpujk","executionInfo":{"status":"ok","timestamp":1764266731487,"user_tz":-540,"elapsed":136,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def custom_collate_fn(batch: List[Dict]):\n","    \"\"\"Noneì„ ë°˜í™˜í•˜ëŠ” ìƒ˜í”Œ(íŒŒì¼ ëˆ„ë½)ì„ í•„í„°ë§í•˜ê³  collate.\"\"\"\n","    # Noneì¸ ìƒ˜í”Œì„ í•„í„°ë§í•©ë‹ˆë‹¤.\n","    batch = [item for item in batch if item is not None]\n","\n","    # ë°°ì¹˜ì— ìœ íš¨í•œ ìƒ˜í”Œì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ None ë°˜í™˜\n","    if not batch:\n","        return None\n","\n","    # ìœ íš¨í•œ ìƒ˜í”Œë§Œ collate\n","    return default_collate(batch)"],"metadata":{"id":"TH1WpbZWyS3b","executionInfo":{"status":"ok","timestamp":1764266731501,"user_tz":-540,"elapsed":6,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["NUM_WORKERS = 4"],"metadata":{"id":"8CF1SyCgyhpR","executionInfo":{"status":"ok","timestamp":1764266731513,"user_tz":-540,"elapsed":6,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# ========================================================\n","# 4. ğŸ ì‹¤í—˜ ì‹¤í–‰ (ì„¸ ê°€ì§€ ë°±ë³¸ ìˆœì°¨ ì§„í–‰)\n","# ========================================================\n","if __name__ == '__main__':\n","    # 1. DataLoader ìƒì„± (ìƒ˜í”Œë§ëœ CSVë¥¼ ì‚¬ìš©)\n","    train_ds = DeepFashionC2S(csv_path=CSV_PATH_LIGHT, img_root=IMG_ROOT_DIR, transform=train_transform, split='train')\n","    val_ds = DeepFashionC2S(csv_path=CSV_PATH_LIGHT, img_root=IMG_ROOT_DIR, transform=val_transform, split='val')\n","\n","    # =========================================================\n","    # ğŸ’¡ [ìˆ˜ì •] DataLoader ìµœì í™” ì„¤ì • (dataset.py ìˆ˜ì • ë¶ˆê°€ ì¡°ê±´)\n","    # =========================================================\n","\n","    # num_workers=0ì„ ìœ ì§€ (ì•ˆì •ì„± í™•ë³´)\n","    # pin_memoryë§Œ Trueë¡œ ë³€ê²½í•˜ì—¬ CPU -> GPU ì „ì†¡ ì†ë„ í–¥ìƒ\n","\n","    # ğŸš¨ [ìˆ˜ì •] DataLoader ìµœì í™” ì„¤ì •\n","    train_dl = DataLoader(\n","        train_ds,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        num_workers=NUM_WORKERS, # ğŸš€ 0 ì´ìƒìœ¼ë¡œ ì„¤ì •\n","        generator=generator,\n","        pin_memory=True,         # ğŸš€ Trueë¡œ ì„¤ì •\n","        collate_fn=custom_collate_fn # ğŸš¨ Custom Collate í•¨ìˆ˜ ì ìš©\n","    )\n","\n","    val_dl = DataLoader(\n","        val_ds,\n","        batch_size=BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=NUM_WORKERS, # ğŸš€ 0 ì´ìƒìœ¼ë¡œ ì„¤ì •\n","        pin_memory=True,         # ğŸš€ Trueë¡œ ì„¤ì •\n","        collate_fn=custom_collate_fn # ğŸš¨ Custom Collate í•¨ìˆ˜ ì ìš©\n","    )\n","    # 2. ë°±ë³¸ ì‹¤í—˜ ë¦¬ìŠ¤íŠ¸\n","    BACKBONES_TO_TEST = ['ResNet-34']\n","    all_results = []\n","\n","    for backbone in BACKBONES_TO_TEST:\n","        print(f\"\\n================ Running Experiment: {backbone} ================\")\n","\n","        # ğŸš¨ Online Semi-Hard Triplet Loss í•¨ìˆ˜ ì „ë‹¬\n","        criterion = online_semi_hard_triplet_loss\n","\n","        results = train_model(backbone, train_dl, val_dl, criterion)\n","        all_results.append(results)\n","\n","    print(\"\\n========== ALL EXPERIMENTS FINAL SUMMARY ==========\")\n","    print(pd.DataFrame(all_results))"],"metadata":{"id":"cboaanAVrGKu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764268113169,"user_tz":-540,"elapsed":1381648,"user":{"displayName":"jw3 lee","userId":"16518102871577890640"}},"outputId":"07b17785-76ee-4c46-9e02-0cf1f16cc7a2"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","================ Running Experiment: ResNet-34 ================\n","Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83.3M/83.3M [00:00<00:00, 141MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["âš ï¸ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n","\n","--- Starting Epoch 1/40 for ResNet-34 ---\n"]},{"output_type":"stream","name":"stderr","text":["Calculating Recall@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:06<00:00,  5.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 | Train Loss: 0.3455 | R@1: 0.502 | R@5: 0.588 | R@10: 0.617\n","\n","--- Starting Epoch 2/40 for ResNet-34 ---\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 2 Train (ResNet-34):   0%|          | 0/389 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Calculating Recall@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:05<00:00,  5.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 | Train Loss: 0.2896 | R@1: 0.475 | R@5: 0.561 | R@10: 0.592\n","\n","--- Starting Epoch 3/40 for ResNet-34 ---\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 3 Train (ResNet-34):   0%|          | 0/389 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Calculating Recall@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:08<00:00,  4.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 | Train Loss: 0.2635 | R@1: 0.533 | R@5: 0.593 | R@10: 0.642\n","\n","--- Starting Epoch 4/40 for ResNet-34 ---\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 4 Train (ResNet-34):   0%|          | 0/389 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Calculating Recall@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:07<00:00,  4.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 | Train Loss: 0.2434 | R@1: 0.513 | R@5: 0.608 | R@10: 0.653\n","\n","--- Starting Epoch 5/40 for ResNet-34 ---\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 5 Train (ResNet-34):   0%|          | 0/389 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Calculating Recall@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:06<00:00,  5.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 | Train Loss: 0.2346 | R@1: 0.506 | R@5: 0.581 | R@10: 0.634\n","\n","--- Starting Epoch 6/40 for ResNet-34 ---\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 6 Train (ResNet-34):   0%|          | 0/389 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Calculating Recall@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:08<00:00,  3.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 | Train Loss: 0.2228 | R@1: 0.505 | R@5: 0.575 | R@10: 0.626\n","\n","--- Starting Epoch 7/40 for ResNet-34 ---\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 7 Train (ResNet-34):   0%|          | 0/389 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Calculating Recall@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:06<00:00,  5.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 | Train Loss: 0.2103 | R@1: 0.515 | R@5: 0.595 | R@10: 0.633\n","\n","--- Starting Epoch 8/40 for ResNet-34 ---\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 8 Train (ResNet-34):   0%|          | 0/389 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Calculating Recall@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:05<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 | Train Loss: 0.2062 | R@1: 0.500 | R@5: 0.566 | R@10: 0.605\n","\n","--- Starting Epoch 9/40 for ResNet-34 ---\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 9 Train (ResNet-34):   0%|          | 0/389 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Calculating Recall@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:09<00:00,  3.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 | Train Loss: 0.2048 | R@1: 0.502 | R@5: 0.591 | R@10: 0.623\n","Early stopping triggered at epoch 9.\n","âœ… í•™ìŠµ ì¬ê°œ: Epoch 4ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤. (ìµœê³  Recall@5: 0.6080)\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating Recall@10:   0%|          | 0/35 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Calculating Recall@10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:08<00:00,  3.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","========================================================\n","ğŸ† ResNet-34 Final Best R@1: 0.5132\n","ğŸ† ResNet-34 Final Best R@5: 0.6080\n","ğŸ† ResNet-34 Final Best R@10: 0.6527\n","========================================================\n","\n","\n","========== ALL EXPERIMENTS FINAL SUMMARY ==========\n","    backbone  final_epoch  best_R@5\n","0  ResNet-34            9  0.608022\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1U-Xly2Cmzm7nFuZKvAXCiJY1vtundcPp","timestamp":1764231988166}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}